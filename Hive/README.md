# Домашнее задание по Hive

## Исходные данные: 

### I. Логи пользователей.

Данные находятся в HDFS по адресу `/data/user_logs/*_M`. Они состоят из трёх частей, каждая из которых находится в своей поддиректории. Данные в каждой части отличаются количеством и типом колонок, разделенных знаками табуляции ('\t') или пробелами.

#### А. Логи запросов пользователей к новостным сообщениям (user_logs).
1. Ip-адрес, с которого пришел запрос (STRING),
2. Время запроса (TIMESTAMP или INT),
3. Пришедший с ip-адреса http-запрос (STRING),
4. Размер переданной клиенту страницы (SMALLINT),
5. Http-статус код (SMALLINT).
6. Информация о клиентском приложении, с которого осуществлялся запрос на сервер, в том числе, информация о браузере (STRING).

**Важно:** информация о браузере содержится в начале 6-ого поля лога (символы с нулевой позиции до позиции первого пробельного символа), содержание оставшейся части строки не определяет браузер пользователя. Разделитель между IP и временем запроса имеет 3 табуляции.

#### B. Информация о пользователях (user_data).
1. IP-адрес (STRING),
2. Браузер пользователя (STRING),
3. Пол (STRING) //male, female,
4. Возраст (TINYINT).

#### С. Информация о местонахождении IP адресов пользователей (ip_data).
1. IP-адрес (STRING),
2. Регион (STRING).

### II. Подсети

Данные находятся по адресу /data/subnets. В директории 3 датасета (/data/subnets/variant[1-3], выберите соответствующий для своего варианта), но все они имеют одинаковый формат.

1. IP-адрес (STRING),
2. Маска подсети (STRING).

Датасеты в каждой директории отличаются 1-м полем.
* 1-й вариант. В качестве 1-го поля дан адрес сети.
* 2-й вариант. Адрес произвольного хоста в сети.
* 3-й вариант. Широковещательный адрес (broadcast).

Семплы находятся в `/data/subnets_S`. Если в полных данных 5000 записей, то в семплах всего 20.

## Задачи

**Задача 1 (411)**. Создайте внешние (EXTERNAL) таблицы по исходным данным. В результате будет 4 таблицы: логи пользователей, данные ip адресов, данные пользователей и подсети. Из таблицы логов перенесите данные в другую таблицу, партицированную по датам – одна партиция на каждый день. На партиционированных таблицах и нужно будет выполнять запросы в следующих задачах.

Требуется, чтобы сериализация и десериализация данных осуществлялась с использованием регулярных выражений (см. `org.apache.hadoop.hive.contrib.serde2.RegexSerDe`, `org.apache.hadoop.hive.serde2.RegexSerDe`).

*Пример результата:*
```
33.49.147.163	http://lenta.ru/4303000	1189	451	Chrome/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0)n	20140101
75.208.40.166	http://newsru.com/3330815	60	306	Safari/5.0 (Windows; U; MSIE 9.0; Windows NT 8.1; Trident/5.0; .NET4.0E; en-AU)n	20140101
```

**Задача 2**. Напишите запрос, выбирающий количество посещений для каждого типа браузера. Браузеры берём из таблицы логов. Если 2 браузера отличаются версиями, считаем их различными.Полученные результаты отсортируйте по убыванию количества.

*Пример результата:*
```
Firefox/5.0	25
Opera/5.0	21
```

**Задача 3**. Напишите запрос, выбирающий количество посещений от мужчин и от женщин по кодам HTTP ответов.

*Пример результата:*
```
511	90675090	39459549
412	87782696	38146030
```
Подсказка для задачи 3: используйте конструкцию [IF](https://www.folkstalk.com/2011/11/conditional-functions-in-hive.html).


**Задача 4**. Создать UDF “мотиватор”. Функция принимает на вход число в виде строки и возвращает 100 - <это число>. Подключите данную функцию к hive и посчитайте, сколько лет осталось до 100 участникам логов. Поведение функции в аварийной ситуации (если на вход подано не число) - на ваше усмотрение (NULL, 0, пустая строка,...). Вывести TOP-10 записей.

*Пример результата:*
```
35
78
77
```


**Задача 5**. Аналогично, только заменяем Safari на Chrome в столбце браузеров.

*Пример результата:*
```
222.131.187.37	20140101	http://news.mail.ru/8805842	1017	416	Opera/5.0
197.72.248.141	20140101	http://news.rambler.ru/2816512	2042	428	Chrome/5.0
```
